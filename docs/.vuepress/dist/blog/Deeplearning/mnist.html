<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>MNIST, Using LeNet | weigao</title>
    <meta name="description" content="...">
    <link rel="icon" href="/android-chrome-512x512.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="theme-color" content="#3eaf7c">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#3eaf7c">
  <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
  <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/assets/css/0.styles.9553969a.css" as="style"><link rel="preload" href="/assets/js/app.8c2dddc1.js" as="script"><link rel="preload" href="/assets/js/5.cd1db3e5.js" as="script"><link rel="preload" href="/assets/js/67.d9fb39f5.js" as="script"><link rel="preload" href="/assets/js/23.2c687b63.js" as="script"><link rel="prefetch" href="/assets/js/1.61fa752c.js"><link rel="prefetch" href="/assets/js/10.2ea75c27.js"><link rel="prefetch" href="/assets/js/100.12e18a8d.js"><link rel="prefetch" href="/assets/js/101.ba47a8ea.js"><link rel="prefetch" href="/assets/js/11.bb91b584.js"><link rel="prefetch" href="/assets/js/12.59472db4.js"><link rel="prefetch" href="/assets/js/13.82dc035e.js"><link rel="prefetch" href="/assets/js/14.3f854a99.js"><link rel="prefetch" href="/assets/js/15.2df0cfd8.js"><link rel="prefetch" href="/assets/js/16.7269e8f3.js"><link rel="prefetch" href="/assets/js/17.b3d4362d.js"><link rel="prefetch" href="/assets/js/18.337eab3d.js"><link rel="prefetch" href="/assets/js/19.dbb75492.js"><link rel="prefetch" href="/assets/js/2.abd16662.js"><link rel="prefetch" href="/assets/js/20.3c6e1006.js"><link rel="prefetch" href="/assets/js/21.48fc9301.js"><link rel="prefetch" href="/assets/js/22.82d214b6.js"><link rel="prefetch" href="/assets/js/24.fa6e8fb7.js"><link rel="prefetch" href="/assets/js/25.738cedaa.js"><link rel="prefetch" href="/assets/js/26.c5def0f6.js"><link rel="prefetch" href="/assets/js/27.2e60968b.js"><link rel="prefetch" href="/assets/js/28.a5d0a7c3.js"><link rel="prefetch" href="/assets/js/29.abf7f7b1.js"><link rel="prefetch" href="/assets/js/30.f056bef0.js"><link rel="prefetch" href="/assets/js/31.b78ba091.js"><link rel="prefetch" href="/assets/js/32.18d30b51.js"><link rel="prefetch" href="/assets/js/33.d700f59d.js"><link rel="prefetch" href="/assets/js/34.c05ed437.js"><link rel="prefetch" href="/assets/js/35.afb321bd.js"><link rel="prefetch" href="/assets/js/36.68bbb287.js"><link rel="prefetch" href="/assets/js/37.e89bdebe.js"><link rel="prefetch" href="/assets/js/38.1f73a8c6.js"><link rel="prefetch" href="/assets/js/39.9ed66f9d.js"><link rel="prefetch" href="/assets/js/4.20b55e5f.js"><link rel="prefetch" href="/assets/js/40.9077eb22.js"><link rel="prefetch" href="/assets/js/41.98693926.js"><link rel="prefetch" href="/assets/js/42.79243cc1.js"><link rel="prefetch" href="/assets/js/43.a7bbba1f.js"><link rel="prefetch" href="/assets/js/44.1f8b8410.js"><link rel="prefetch" href="/assets/js/45.51c6b033.js"><link rel="prefetch" href="/assets/js/46.6cb9eac9.js"><link rel="prefetch" href="/assets/js/47.1105348d.js"><link rel="prefetch" href="/assets/js/48.f85d7876.js"><link rel="prefetch" href="/assets/js/49.009aab65.js"><link rel="prefetch" href="/assets/js/50.0f427177.js"><link rel="prefetch" href="/assets/js/51.13b2a5c0.js"><link rel="prefetch" href="/assets/js/52.cbc4eeea.js"><link rel="prefetch" href="/assets/js/53.2374bd93.js"><link rel="prefetch" href="/assets/js/54.34cf31bb.js"><link rel="prefetch" href="/assets/js/55.1d7e3563.js"><link rel="prefetch" href="/assets/js/56.647d3fbf.js"><link rel="prefetch" href="/assets/js/57.81a8354f.js"><link rel="prefetch" href="/assets/js/58.ac99e744.js"><link rel="prefetch" href="/assets/js/59.e3bb8a78.js"><link rel="prefetch" href="/assets/js/6.46455cb0.js"><link rel="prefetch" href="/assets/js/60.76f1be0c.js"><link rel="prefetch" href="/assets/js/61.547bf157.js"><link rel="prefetch" href="/assets/js/62.bb2d5f35.js"><link rel="prefetch" href="/assets/js/63.e4c325f4.js"><link rel="prefetch" href="/assets/js/64.39937791.js"><link rel="prefetch" href="/assets/js/65.79722d0a.js"><link rel="prefetch" href="/assets/js/66.16a77a10.js"><link rel="prefetch" href="/assets/js/68.c266e649.js"><link rel="prefetch" href="/assets/js/69.6a56611b.js"><link rel="prefetch" href="/assets/js/7.d6c547e2.js"><link rel="prefetch" href="/assets/js/70.b9c6794f.js"><link rel="prefetch" href="/assets/js/71.319f7350.js"><link rel="prefetch" href="/assets/js/72.e07abb24.js"><link rel="prefetch" href="/assets/js/73.0406a3c6.js"><link rel="prefetch" href="/assets/js/74.9b41ca8d.js"><link rel="prefetch" href="/assets/js/75.ce841083.js"><link rel="prefetch" href="/assets/js/76.b8a63a09.js"><link rel="prefetch" href="/assets/js/77.44094ede.js"><link rel="prefetch" href="/assets/js/78.5d2d7624.js"><link rel="prefetch" href="/assets/js/79.89aa3f8f.js"><link rel="prefetch" href="/assets/js/8.2135ddb7.js"><link rel="prefetch" href="/assets/js/80.9b79b455.js"><link rel="prefetch" href="/assets/js/81.b9c4e6cc.js"><link rel="prefetch" href="/assets/js/82.c089b765.js"><link rel="prefetch" href="/assets/js/83.368be746.js"><link rel="prefetch" href="/assets/js/84.0ad20007.js"><link rel="prefetch" href="/assets/js/85.bed6c2b0.js"><link rel="prefetch" href="/assets/js/86.a567014d.js"><link rel="prefetch" href="/assets/js/87.e4edfddc.js"><link rel="prefetch" href="/assets/js/88.73d31df8.js"><link rel="prefetch" href="/assets/js/89.6d4e53cb.js"><link rel="prefetch" href="/assets/js/9.d01dceaa.js"><link rel="prefetch" href="/assets/js/90.0129f07f.js"><link rel="prefetch" href="/assets/js/91.d16664ce.js"><link rel="prefetch" href="/assets/js/92.06e8dcff.js"><link rel="prefetch" href="/assets/js/93.b5b18dd9.js"><link rel="prefetch" href="/assets/js/94.84d5e718.js"><link rel="prefetch" href="/assets/js/95.eb85deaa.js"><link rel="prefetch" href="/assets/js/96.a9514789.js"><link rel="prefetch" href="/assets/js/97.8b1d193f.js"><link rel="prefetch" href="/assets/js/98.82feff02.js"><link rel="prefetch" href="/assets/js/99.7f6f4c17.js">
    <link rel="stylesheet" href="/assets/css/0.styles.9553969a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">weigao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>MNIST, Using LeNet</span> <!----></p> <!----></section></li></ul> </aside> <main class="page"> <div class="content default"><h1 id="mnist-using-lenet"><a href="#mnist-using-lenet" aria-hidden="true" class="header-anchor">#</a> MNIST, Using LeNet</h1> <div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#mnist_inference.py</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

INPUT_NODE <span class="token operator">=</span> <span class="token number">784</span>
OUTPUT_NODE <span class="token operator">=</span> <span class="token number">10</span>
LAYER1_NODE <span class="token operator">=</span> <span class="token number">500</span>

<span class="token keyword">def</span> <span class="token function">get_weight_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;weights&quot;</span><span class="token punctuation">,</span> shape<span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> regularizer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span> tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> weights


<span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer1'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>

        weights <span class="token operator">=</span> get_weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>INPUT_NODE<span class="token punctuation">,</span> LAYER1_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span>
        biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;biases&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>LAYER1_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layer1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> weights<span class="token punctuation">)</span> <span class="token operator">+</span> biases<span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        weights <span class="token operator">=</span> get_weight_variable<span class="token punctuation">(</span><span class="token punctuation">[</span>LAYER1_NODE<span class="token punctuation">,</span> OUTPUT_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span>
        biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;biases&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>OUTPUT_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layer2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>layer1<span class="token punctuation">,</span> weights<span class="token punctuation">)</span> <span class="token operator">+</span> biases

    <span class="token keyword">return</span> layer2
</code></pre></div><div class="language-python extra-class"><pre class="language-python"><code><span class="token comment">#mnist_test.py</span>
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">from</span> tensorflow<span class="token punctuation">.</span>examples<span class="token punctuation">.</span>tutorials<span class="token punctuation">.</span>mnist <span class="token keyword">import</span> input_data
<span class="token keyword">import</span> mnist_inference
<span class="token keyword">import</span> os

BATCH_SIZE <span class="token operator">=</span> <span class="token number">100</span>
LEARNING_RATE_BASE <span class="token operator">=</span> <span class="token number">0.8</span>
LEARNING_RATE_DECAY <span class="token operator">=</span> <span class="token number">0.99</span>
REGULARIZATION_RATE <span class="token operator">=</span> <span class="token number">0.0001</span>
TRAINING_STEPS <span class="token operator">=</span> <span class="token number">30000</span>
MOVING_AVERAGE_DECAY <span class="token operator">=</span> <span class="token number">0.99</span>
MODEL_SAVE_PATH <span class="token operator">=</span> <span class="token string">&quot;MNIST_model/&quot;</span>
MODEL_NAME <span class="token operator">=</span> <span class="token string">&quot;mnist_model&quot;</span>


<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>mnist<span class="token punctuation">)</span><span class="token punctuation">:</span>

    x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> mnist_inference<span class="token punctuation">.</span>INPUT_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'x-input'</span><span class="token punctuation">)</span>
    y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> mnist_inference<span class="token punctuation">.</span>OUTPUT_NODE<span class="token punctuation">]</span><span class="token punctuation">,</span> name<span class="token operator">=</span><span class="token string">'y-input'</span><span class="token punctuation">)</span>

    regularizer <span class="token operator">=</span> tf<span class="token punctuation">.</span>contrib<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>l2_regularizer<span class="token punctuation">(</span>REGULARIZATION_RATE<span class="token punctuation">)</span>
    y <span class="token operator">=</span> mnist_inference<span class="token punctuation">.</span>inference<span class="token punctuation">(</span>x<span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span>
    global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> trainable<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>


    variable_averages <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>ExponentialMovingAverage<span class="token punctuation">(</span>MOVING_AVERAGE_DECAY<span class="token punctuation">,</span> global_step<span class="token punctuation">)</span>
    variables_averages_op <span class="token operator">=</span> variable_averages<span class="token punctuation">.</span><span class="token builtin">apply</span><span class="token punctuation">(</span>tf<span class="token punctuation">.</span>trainable_variables<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cross_entropy <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>sparse_softmax_cross_entropy_with_logits<span class="token punctuation">(</span>logits<span class="token operator">=</span>y<span class="token punctuation">,</span> labels<span class="token operator">=</span>tf<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>y_<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token comment">#当分类问题只有一个正确答案时，可以使用sparse_softmax_cross_entropy_with_logits函数来加速交叉熵的计算</span>
    cross_entropy_mean <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> cross_entropy_mean <span class="token operator">+</span> tf<span class="token punctuation">.</span>add_n<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>get_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
	<span class="token comment">#总损失等于交叉熵损失和正则化损失的和</span>
    learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span>
        LEARNING_RATE_BASE<span class="token punctuation">,</span>
        global_step<span class="token punctuation">,</span>
        mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>num_examples <span class="token operator">/</span> BATCH_SIZE<span class="token punctuation">,</span> LEARNING_RATE_DECAY<span class="token punctuation">,</span>
		<span class="token comment">#过完所有的训练数据需要的迭代次数，dacay_steps和dacay_rate</span>
        staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>GradientDescentOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">,</span> global_step<span class="token operator">=</span>global_step<span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>control_dependencies<span class="token punctuation">(</span><span class="token punctuation">[</span>train_step<span class="token punctuation">,</span> variables_averages_op<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        train_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>no_op<span class="token punctuation">(</span>name<span class="token operator">=</span><span class="token string">'train'</span><span class="token punctuation">)</span>


    saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
        tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>TRAINING_STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
            xs<span class="token punctuation">,</span> ys <span class="token operator">=</span> mnist<span class="token punctuation">.</span>train<span class="token punctuation">.</span>next_batch<span class="token punctuation">(</span>BATCH_SIZE<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> loss_value<span class="token punctuation">,</span> step <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>train_op<span class="token punctuation">,</span> loss<span class="token punctuation">,</span> global_step<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> xs<span class="token punctuation">,</span> y_<span class="token punctuation">:</span> ys<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training step(s), loss on training batch is %g.&quot;</span> <span class="token operator">%</span> <span class="token punctuation">(</span>step<span class="token punctuation">,</span> loss_value<span class="token punctuation">)</span><span class="token punctuation">)</span>
                saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>sess<span class="token punctuation">,</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>MODEL_SAVE_PATH<span class="token punctuation">,</span> MODEL_NAME<span class="token punctuation">)</span><span class="token punctuation">,</span> global_step<span class="token operator">=</span>global_step<span class="token punctuation">)</span>


<span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span>argv<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    mnist <span class="token operator">=</span> input_data<span class="token punctuation">.</span>read_data_sets<span class="token punctuation">(</span><span class="token string">&quot;../../../datasets/MNIST_data&quot;</span><span class="token punctuation">,</span> one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    train<span class="token punctuation">(</span>mnist<span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    tf<span class="token punctuation">.</span>app<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">)</span>


</code></pre></div><p><code>mnist.train.next_batch(batch_size)</code></p> <p>可以方便使用随机梯度下降，从所有的训练数据中读取一小部分作为一个训练batch。
在损失函数中，每次计算一小部分训练数据的损失函数，这一小部分数据被称之为一个<strong>batch</strong>，每次使用一个batch可以大大减少收敛所需要的迭代次数，同时可以使收敛到的结果更加接近梯度下降的效果。
要很好地理解batch存在的意义，可以对比Full Batch Learning的思想；如果batch_size = 1，那么就变成了“在线学习”，在线学习难以达到收敛。所以，选择一个适当的batch size非常重要，过小可能导致不收敛，过大可能导致迭代速度过慢。</p> <p>对于<strong>滑动平均模型</strong>，这是一个使模型在测试数据上更robust的方法，在采用随机梯度下降算法训练神经网络时，使用滑动平均模型在很多应用中都可以在一定程度提高数据模型在测试数据上的表现。
要实现这个模型，可以使用TensorFlow提供的</p> <p><code>tf.train.ExponentialMovingAverage</code></p> <p>在实现时，需要提供一个衰减率(dacay)，用于控制模型的更新速度，一般dacay越大模型越趋于稳定，实际应用中一般会设置为一个很接近1的数字，使得模型可以在训练前期更新地更快。</p> <h3 id="lenet实现mnist"><a href="#lenet实现mnist" aria-hidden="true" class="header-anchor">#</a> LeNet实现mnist</h3> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

<span class="token keyword">def</span> <span class="token function">get_weight_variable</span><span class="token punctuation">(</span>shape<span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
        <span class="token string">&quot;weights&quot;</span><span class="token punctuation">,</span> shape<span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span>stddev<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> regularizer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">(</span>weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> weights

<span class="token keyword">def</span> <span class="token function">inference</span><span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> train<span class="token punctuation">,</span> regularizer<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer1-conv1'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        conv1_weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;weight&quot;</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>
                                        <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># why [5,5,1,32] there? [卷积核高度，卷积核宽度，通道数，卷积核数量]</span>
		<span class="token comment">#conv2d:Computes a 2-D convolution given 4-D `input` and `filter` tensors.</span>
        conv1_biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
            <span class="token string">&quot;bias&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">32</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        conv1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>input_tensor<span class="token punctuation">,</span> conv1_weights<span class="token punctuation">,</span>
                             strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
        relu1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv1<span class="token punctuation">,</span> conv1_biases<span class="token punctuation">)</span><span class="token punctuation">)</span>
		<span class="token comment">#Unlike `tf.add`, the type of `bias` is allowed to differ from `value` in the case where both types are quantized.</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer2-pool1'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pool1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>relu1<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span>
                               <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer3-conv2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        conv2_weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;weight&quot;</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># why [5,5,32,64] there</span>
        conv2_biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
            <span class="token string">&quot;bias&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">64</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        conv2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>relu1<span class="token punctuation">,</span> conv2_weights<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span>
                             <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>
        relu2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>bias_add<span class="token punctuation">(</span>conv2<span class="token punctuation">,</span> conv2_biases<span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer4-pool2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        pool2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>relu2<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span>
                               <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">'SAME'</span><span class="token punctuation">)</span>

    pool_shape <span class="token operator">=</span> pool2<span class="token punctuation">.</span>get_shape<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>as_list<span class="token punctuation">(</span><span class="token punctuation">)</span>
    nodes <span class="token operator">=</span> pool_shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> pool_shape<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">*</span> pool_shape<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span>
    reshaped <span class="token operator">=</span> tf<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>pool2<span class="token punctuation">,</span> <span class="token punctuation">[</span>pool_shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> nodes<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer5-fc1'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        fc1_weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span><span class="token string">&quot;weights&quot;</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span>
                                      nodes<span class="token punctuation">,</span> <span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token comment"># why there 512</span>
        <span class="token keyword">if</span> regularizer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">'losses'</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">(</span>fc1_weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fc1_biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
            <span class="token string">&quot;bias&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        fc1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>reshaped<span class="token punctuation">,</span> fc1_weights<span class="token punctuation">)</span> <span class="token operator">+</span> fc1_biases<span class="token punctuation">)</span>
        <span class="token comment"># how to think about matmul</span>

        <span class="token keyword">if</span> train<span class="token punctuation">:</span>
            fc1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>dropout<span class="token punctuation">(</span>fc1<span class="token punctuation">,</span> <span class="token number">0.5</span><span class="token punctuation">)</span>

    <span class="token keyword">with</span> tf<span class="token punctuation">.</span>variable_scope<span class="token punctuation">(</span><span class="token string">'layer6-fc2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        fc2_weights <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
            <span class="token string">&quot;weights&quot;</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">512</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>truncated_normal_initializer<span class="token punctuation">(</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> regularizer <span class="token operator">!=</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
            tf<span class="token punctuation">.</span>add_to_collection<span class="token punctuation">(</span><span class="token string">&quot;losses&quot;</span><span class="token punctuation">,</span> regularizer<span class="token punctuation">(</span>fc2_weights<span class="token punctuation">)</span><span class="token punctuation">)</span>
        fc2_biases <span class="token operator">=</span> tf<span class="token punctuation">.</span>get_variable<span class="token punctuation">(</span>
            <span class="token string">&quot;bias&quot;</span><span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">]</span><span class="token punctuation">,</span> initializer<span class="token operator">=</span>tf<span class="token punctuation">.</span>constant_initializer<span class="token punctuation">(</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        logit <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>fc1<span class="token punctuation">,</span> fc2_weights<span class="token punctuation">)</span> <span class="token operator">+</span> fc2_biases

    <span class="token keyword">return</span> logit
</code></pre></div></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">4/28/2019, 5:57:40 PM</span></div></footer> <!----> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.8c2dddc1.js" defer></script><script src="/assets/js/5.cd1db3e5.js" defer></script><script src="/assets/js/67.d9fb39f5.js" defer></script><script src="/assets/js/23.2c687b63.js" defer></script>
  </body>
</html>
