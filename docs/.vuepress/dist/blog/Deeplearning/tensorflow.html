<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>TensorFlow | weigao</title>
    <meta name="description" content="...">
    <link rel="icon" href="/android-chrome-512x512.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="theme-color" content="#3eaf7c">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#3eaf7c">
  <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
  <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/assets/css/0.styles.7f8e8e17.css" as="style"><link rel="preload" href="/assets/js/app.04f618ac.js" as="script"><link rel="preload" href="/assets/js/4.786e9641.js" as="script"><link rel="preload" href="/assets/js/69.3076ac6c.js" as="script"><link rel="preload" href="/assets/js/22.8a1e30c6.js" as="script"><link rel="prefetch" href="/assets/js/1.4d845e0f.js"><link rel="prefetch" href="/assets/js/10.cb991f27.js"><link rel="prefetch" href="/assets/js/100.166bc196.js"><link rel="prefetch" href="/assets/js/101.e7cffef0.js"><link rel="prefetch" href="/assets/js/11.bdee8adf.js"><link rel="prefetch" href="/assets/js/12.0de60934.js"><link rel="prefetch" href="/assets/js/13.22e5ae3c.js"><link rel="prefetch" href="/assets/js/14.60349479.js"><link rel="prefetch" href="/assets/js/15.e90da1aa.js"><link rel="prefetch" href="/assets/js/16.d46a3f03.js"><link rel="prefetch" href="/assets/js/17.08b43f37.js"><link rel="prefetch" href="/assets/js/18.540ea5c0.js"><link rel="prefetch" href="/assets/js/19.2a3cffb5.js"><link rel="prefetch" href="/assets/js/20.dd893499.js"><link rel="prefetch" href="/assets/js/21.99dcbff2.js"><link rel="prefetch" href="/assets/js/23.ea67e33d.js"><link rel="prefetch" href="/assets/js/24.849c6af0.js"><link rel="prefetch" href="/assets/js/25.6f9017b1.js"><link rel="prefetch" href="/assets/js/26.bdeb4817.js"><link rel="prefetch" href="/assets/js/27.c92505b7.js"><link rel="prefetch" href="/assets/js/28.89df187a.js"><link rel="prefetch" href="/assets/js/29.616cb493.js"><link rel="prefetch" href="/assets/js/3.95660ab1.js"><link rel="prefetch" href="/assets/js/30.f5dad746.js"><link rel="prefetch" href="/assets/js/31.8f09a1ee.js"><link rel="prefetch" href="/assets/js/32.096a4997.js"><link rel="prefetch" href="/assets/js/33.80e31410.js"><link rel="prefetch" href="/assets/js/34.55accda6.js"><link rel="prefetch" href="/assets/js/35.7bcfea9f.js"><link rel="prefetch" href="/assets/js/36.70334ad2.js"><link rel="prefetch" href="/assets/js/37.adfd7377.js"><link rel="prefetch" href="/assets/js/38.c6c2caf5.js"><link rel="prefetch" href="/assets/js/39.57f3f29f.js"><link rel="prefetch" href="/assets/js/40.ba046e6e.js"><link rel="prefetch" href="/assets/js/41.362b144b.js"><link rel="prefetch" href="/assets/js/42.e617596d.js"><link rel="prefetch" href="/assets/js/43.e42dc836.js"><link rel="prefetch" href="/assets/js/44.64b146d7.js"><link rel="prefetch" href="/assets/js/45.c8012cad.js"><link rel="prefetch" href="/assets/js/46.1a47e167.js"><link rel="prefetch" href="/assets/js/47.043d2168.js"><link rel="prefetch" href="/assets/js/48.684c54ed.js"><link rel="prefetch" href="/assets/js/49.94d9e282.js"><link rel="prefetch" href="/assets/js/5.a58c921c.js"><link rel="prefetch" href="/assets/js/50.4bbd57ab.js"><link rel="prefetch" href="/assets/js/51.4532174d.js"><link rel="prefetch" href="/assets/js/52.95d01fd3.js"><link rel="prefetch" href="/assets/js/53.ec487bcb.js"><link rel="prefetch" href="/assets/js/54.85310694.js"><link rel="prefetch" href="/assets/js/55.970a70bb.js"><link rel="prefetch" href="/assets/js/56.282912ee.js"><link rel="prefetch" href="/assets/js/57.71bba221.js"><link rel="prefetch" href="/assets/js/58.cee58c7b.js"><link rel="prefetch" href="/assets/js/59.9dc76997.js"><link rel="prefetch" href="/assets/js/6.7c76b460.js"><link rel="prefetch" href="/assets/js/60.51e84112.js"><link rel="prefetch" href="/assets/js/61.2f70800b.js"><link rel="prefetch" href="/assets/js/62.fb65d368.js"><link rel="prefetch" href="/assets/js/63.84802651.js"><link rel="prefetch" href="/assets/js/64.6d9fb704.js"><link rel="prefetch" href="/assets/js/65.811b4d0d.js"><link rel="prefetch" href="/assets/js/66.8204802d.js"><link rel="prefetch" href="/assets/js/67.95562b82.js"><link rel="prefetch" href="/assets/js/68.62f5bbcc.js"><link rel="prefetch" href="/assets/js/7.ef39b2d1.js"><link rel="prefetch" href="/assets/js/70.493c24d3.js"><link rel="prefetch" href="/assets/js/71.dd6e6c35.js"><link rel="prefetch" href="/assets/js/72.115466c2.js"><link rel="prefetch" href="/assets/js/73.bba26d6d.js"><link rel="prefetch" href="/assets/js/74.f426ace3.js"><link rel="prefetch" href="/assets/js/75.24fe4798.js"><link rel="prefetch" href="/assets/js/76.1c27311a.js"><link rel="prefetch" href="/assets/js/77.9fef2546.js"><link rel="prefetch" href="/assets/js/78.db7a1282.js"><link rel="prefetch" href="/assets/js/79.34b008b9.js"><link rel="prefetch" href="/assets/js/8.e13b994b.js"><link rel="prefetch" href="/assets/js/80.2ca90b1f.js"><link rel="prefetch" href="/assets/js/81.9c330f4e.js"><link rel="prefetch" href="/assets/js/82.750d6063.js"><link rel="prefetch" href="/assets/js/83.65e24da2.js"><link rel="prefetch" href="/assets/js/84.a5dae379.js"><link rel="prefetch" href="/assets/js/85.a268f7f2.js"><link rel="prefetch" href="/assets/js/86.27035b07.js"><link rel="prefetch" href="/assets/js/87.1f662c65.js"><link rel="prefetch" href="/assets/js/88.08d13430.js"><link rel="prefetch" href="/assets/js/89.d281d063.js"><link rel="prefetch" href="/assets/js/9.dad742b6.js"><link rel="prefetch" href="/assets/js/90.d07b37a5.js"><link rel="prefetch" href="/assets/js/91.b48e5d14.js"><link rel="prefetch" href="/assets/js/92.16b95250.js"><link rel="prefetch" href="/assets/js/93.4fe2816e.js"><link rel="prefetch" href="/assets/js/94.c5362b99.js"><link rel="prefetch" href="/assets/js/95.42757d01.js"><link rel="prefetch" href="/assets/js/96.a0d98f7e.js"><link rel="prefetch" href="/assets/js/97.03492270.js"><link rel="prefetch" href="/assets/js/98.015b484d.js"><link rel="prefetch" href="/assets/js/99.14771760.js">
    <link rel="stylesheet" href="/assets/css/0.styles.7f8e8e17.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">weigao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>TensorFlow</span> <!----></p> <!----></section></li></ul> </aside> <main class="page"> <div class="content default"><h1 id="tensorflow"><a href="#tensorflow" aria-hidden="true" class="header-anchor">#</a> TensorFlow</h1> <p>Tensorflow中一些简单但是容易忘记的：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token comment">#用来表示矩阵的乘法操作</span>

weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#偏置项</span>
</code></pre></div><p>tf.Variable为初始化变量的操作，tf.random_normal指定了一个2*3的矩阵，元素均值为0，标准差为2，并且，符合正态分布，其他的可以参考tensorflow随机数生成函数</p> <p>接下来这段代码实现神经网络的<strong>前向传播</strong>过程</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>

sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>关于placeholder</strong>
一般而言，我们需要使用常量：</p> <p><code>x = tf.constant([[0.7,0.9]])</code></p> <p>但是这样明显加大了tensorflow的计算量，所以引入了placeholder，这时候我们只需要将数据传入计算图，下面是一个例子：</p> <p><code>x = tf.placeholder(tf.float32,shape = (1,2), name = &quot;input&quot;)</code></p> <p>其中的shape属性可以不指定，因为数据的维度信息可以根据提供的数据推导得出，但是确定的维度的给出可以降低出错的概论。下面的代码为placeholder实现前向传播算法：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>

<span class="token comment"># print(sess.run(y))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>需要注意的是被注释的那行代码<code># print(sess.run(y))</code>，如果运行的话，解释器会报告一个错误，这是因为我们需要提供一个feed_dict来指定x的取值。
如果我们需要多个样例的传播结果，只需要：</p> <p><code>x = tf.placeholder(tf.float32,shape=(3,2),name=&quot;input&quot;)</code> #3个</p> <p>然后给出三组数据即可：</p> <p><code>sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]})</code></p> <p>而后我们定义loss函数来刻画预测值和真实值之间的差距，然后通过反向传播算法来调整神经网络的取值从而缩小差距</p> <div class="language-python extra-class"><pre class="language-python"><code>cross_entropy <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>y_ <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
</code></pre></div><p>cross_entropy定义了真实值和预测值之间的<em>交叉熵</em>。
具体而言，交叉熵刚开始的意义是刻画了两个概论分布之间的距离，是分类问题中使用比较广的一种损失函数。在代码中的含义就是y`表示正确结果，y代表预测结果,并且将张量中的数值限制在1E-10~1.0之间，以避免一些运算错误
如果与softmax一起使用的话，tensorflow对这两个功能进行了统一封装，调用</p> <p><code>cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)</code></p> <p>下面是训练过程开始的代码：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    STEPS <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> dataset_size<span class="token punctuation">)</span>

        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">,</span> y_<span class="token punctuation">:</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            total_cross_entropy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training steps,cross entropy is %g&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>total_cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>训练循环了5000次，可以观察到交叉熵的值是越来越小的，这表明预测的结果和真实值的差距越来越小
最后的两行输出表示训练之后神经网络的值</p> <p>**总结一下，训练神经网络的过程可以分为以下三个步骤：</p> <ul><li>定义网络的结构和前向传播的输出</li> <li>定义损失函数和选择反向传播优化的算法</li> <li>生成会话并且在训练数据上反复运行反向传播优化算法**</li></ul> <p>有的时候需要自定义损失函数：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> RandomState

batch_size <span class="token operator">=</span> <span class="token number">8</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'x-input'</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'y-input'</span><span class="token punctuation">)</span>

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>seed <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>

loss_less <span class="token operator">=</span> <span class="token number">10</span>
loss_more <span class="token operator">=</span> <span class="token number">1</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>y<span class="token punctuation">,</span>y_<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>y<span class="token operator">-</span>y_<span class="token punctuation">)</span><span class="token operator">*</span>loss_more<span class="token punctuation">,</span><span class="token punctuation">(</span>y_<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>loss_less<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

rdm <span class="token operator">=</span> RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
dataset_size <span class="token operator">=</span> <span class="token number">128</span>
X <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>dataset_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token operator">+</span>x2<span class="token operator">+</span>rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">10.0</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token keyword">in</span> X<span class="token punctuation">]</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    Steps <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>dataset_size<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre></div><p>以上自定义了一个损失函数，实际值和预测值之间存在的差值分配不用的系数，我们也可以使用均方误差(MSE)：</p> <p><code>loss = tf.reduce_mean(tf.square(y_-y))</code></p> <p>通过比较输出的结果可以看出，不同的损失函数会对模型产生重要影响。</p> <p>在优化参数的时候，梯度下降法是最常用的神经网络优化算法，具体而言，对于一个优化算法而言，第一步随机产生一个参数的初始值，然后通过梯度和学习率来更新参数的取值。
梯度下降算法的两个缺陷：第一是可能得到局部最优的结果，第二是计算时间太长，因为要计算所有训练数据的损失函数是非常耗时间的，所以就可以使用随机梯度下降算法，具体而言，就是在每一轮的迭代中，随机优化某一条训练数据上的损失函数，但是随机梯度下降法有的时候甚至无法达到局部最优，所以一般采用<strong>每次计算一小部分训练数据的损失函数</strong>的方法，这一小部分数据称为一个batch。</p> <p>对于learning_rate，常用的是指数衰减法</p> <div class="language-python extra-class"><pre class="language-python"><code>global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span>global_step<span class="token punctuation">,</span> <span class="token number">100</span> <span class="token punctuation">,</span> <span class="token number">0.96</span> <span class="token punctuation">,</span>staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>dacay_steps代表了完整的使用一遍训练数据所需要的迭代轮数（总训练样本数除以每一个batch的训练样本数），staircase的值为True时，global_step/decay_steps会被转化成整数。上面各个参数的含义是每训练100轮后学习率乘以0.96。经验有助于设置好学习率、衰减系数和衰减速度。</p> <div class="language-python extra-class"><pre class="language-python"><code>batch_size <span class="token operator">=</span> n

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>

loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
	<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
		current_X<span class="token punctuation">,</span>surrent_Y <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
		sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_sict <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>current_X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>current_Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre></div><p>以上代码概括了一般神经网络的训练大致遵循的过程。</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">4/28/2019, 5:57:40 PM</span></div></footer> <!----> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.04f618ac.js" defer></script><script src="/assets/js/4.786e9641.js" defer></script><script src="/assets/js/69.3076ac6c.js" defer></script><script src="/assets/js/22.8a1e30c6.js" defer></script>
  </body>
</html>
