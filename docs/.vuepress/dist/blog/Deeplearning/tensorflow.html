<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>TensorFlow | weigao</title>
    <meta name="description" content="...">
    <link rel="icon" href="/android-chrome-512x512.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="theme-color" content="#3eaf7c">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  <link rel="apple-touch-icon" href="/icons/apple-touch-icon-152x152.png">
  <link rel="mask-icon" href="/icons/safari-pinned-tab.svg" color="#3eaf7c">
  <meta name="msapplication-TileImage" content="/icons/msapplication-icon-144x144.png">
  <meta name="msapplication-TileColor" content="#000000">
    
    <link rel="preload" href="/assets/css/0.styles.9553969a.css" as="style"><link rel="preload" href="/assets/js/app.8c2dddc1.js" as="script"><link rel="preload" href="/assets/js/5.cd1db3e5.js" as="script"><link rel="preload" href="/assets/js/69.6a56611b.js" as="script"><link rel="preload" href="/assets/js/23.2c687b63.js" as="script"><link rel="prefetch" href="/assets/js/1.61fa752c.js"><link rel="prefetch" href="/assets/js/10.2ea75c27.js"><link rel="prefetch" href="/assets/js/100.12e18a8d.js"><link rel="prefetch" href="/assets/js/101.ba47a8ea.js"><link rel="prefetch" href="/assets/js/11.bb91b584.js"><link rel="prefetch" href="/assets/js/12.59472db4.js"><link rel="prefetch" href="/assets/js/13.82dc035e.js"><link rel="prefetch" href="/assets/js/14.3f854a99.js"><link rel="prefetch" href="/assets/js/15.2df0cfd8.js"><link rel="prefetch" href="/assets/js/16.7269e8f3.js"><link rel="prefetch" href="/assets/js/17.b3d4362d.js"><link rel="prefetch" href="/assets/js/18.337eab3d.js"><link rel="prefetch" href="/assets/js/19.dbb75492.js"><link rel="prefetch" href="/assets/js/2.abd16662.js"><link rel="prefetch" href="/assets/js/20.3c6e1006.js"><link rel="prefetch" href="/assets/js/21.48fc9301.js"><link rel="prefetch" href="/assets/js/22.82d214b6.js"><link rel="prefetch" href="/assets/js/24.fa6e8fb7.js"><link rel="prefetch" href="/assets/js/25.738cedaa.js"><link rel="prefetch" href="/assets/js/26.c5def0f6.js"><link rel="prefetch" href="/assets/js/27.2e60968b.js"><link rel="prefetch" href="/assets/js/28.a5d0a7c3.js"><link rel="prefetch" href="/assets/js/29.abf7f7b1.js"><link rel="prefetch" href="/assets/js/30.f056bef0.js"><link rel="prefetch" href="/assets/js/31.b78ba091.js"><link rel="prefetch" href="/assets/js/32.18d30b51.js"><link rel="prefetch" href="/assets/js/33.d700f59d.js"><link rel="prefetch" href="/assets/js/34.c05ed437.js"><link rel="prefetch" href="/assets/js/35.afb321bd.js"><link rel="prefetch" href="/assets/js/36.68bbb287.js"><link rel="prefetch" href="/assets/js/37.e89bdebe.js"><link rel="prefetch" href="/assets/js/38.1f73a8c6.js"><link rel="prefetch" href="/assets/js/39.9ed66f9d.js"><link rel="prefetch" href="/assets/js/4.20b55e5f.js"><link rel="prefetch" href="/assets/js/40.9077eb22.js"><link rel="prefetch" href="/assets/js/41.98693926.js"><link rel="prefetch" href="/assets/js/42.79243cc1.js"><link rel="prefetch" href="/assets/js/43.a7bbba1f.js"><link rel="prefetch" href="/assets/js/44.1f8b8410.js"><link rel="prefetch" href="/assets/js/45.51c6b033.js"><link rel="prefetch" href="/assets/js/46.6cb9eac9.js"><link rel="prefetch" href="/assets/js/47.1105348d.js"><link rel="prefetch" href="/assets/js/48.f85d7876.js"><link rel="prefetch" href="/assets/js/49.009aab65.js"><link rel="prefetch" href="/assets/js/50.0f427177.js"><link rel="prefetch" href="/assets/js/51.13b2a5c0.js"><link rel="prefetch" href="/assets/js/52.cbc4eeea.js"><link rel="prefetch" href="/assets/js/53.2374bd93.js"><link rel="prefetch" href="/assets/js/54.34cf31bb.js"><link rel="prefetch" href="/assets/js/55.1d7e3563.js"><link rel="prefetch" href="/assets/js/56.647d3fbf.js"><link rel="prefetch" href="/assets/js/57.81a8354f.js"><link rel="prefetch" href="/assets/js/58.ac99e744.js"><link rel="prefetch" href="/assets/js/59.e3bb8a78.js"><link rel="prefetch" href="/assets/js/6.46455cb0.js"><link rel="prefetch" href="/assets/js/60.76f1be0c.js"><link rel="prefetch" href="/assets/js/61.547bf157.js"><link rel="prefetch" href="/assets/js/62.bb2d5f35.js"><link rel="prefetch" href="/assets/js/63.e4c325f4.js"><link rel="prefetch" href="/assets/js/64.39937791.js"><link rel="prefetch" href="/assets/js/65.79722d0a.js"><link rel="prefetch" href="/assets/js/66.16a77a10.js"><link rel="prefetch" href="/assets/js/67.d9fb39f5.js"><link rel="prefetch" href="/assets/js/68.c266e649.js"><link rel="prefetch" href="/assets/js/7.d6c547e2.js"><link rel="prefetch" href="/assets/js/70.b9c6794f.js"><link rel="prefetch" href="/assets/js/71.319f7350.js"><link rel="prefetch" href="/assets/js/72.e07abb24.js"><link rel="prefetch" href="/assets/js/73.0406a3c6.js"><link rel="prefetch" href="/assets/js/74.9b41ca8d.js"><link rel="prefetch" href="/assets/js/75.ce841083.js"><link rel="prefetch" href="/assets/js/76.b8a63a09.js"><link rel="prefetch" href="/assets/js/77.44094ede.js"><link rel="prefetch" href="/assets/js/78.5d2d7624.js"><link rel="prefetch" href="/assets/js/79.89aa3f8f.js"><link rel="prefetch" href="/assets/js/8.2135ddb7.js"><link rel="prefetch" href="/assets/js/80.9b79b455.js"><link rel="prefetch" href="/assets/js/81.b9c4e6cc.js"><link rel="prefetch" href="/assets/js/82.c089b765.js"><link rel="prefetch" href="/assets/js/83.368be746.js"><link rel="prefetch" href="/assets/js/84.0ad20007.js"><link rel="prefetch" href="/assets/js/85.bed6c2b0.js"><link rel="prefetch" href="/assets/js/86.a567014d.js"><link rel="prefetch" href="/assets/js/87.e4edfddc.js"><link rel="prefetch" href="/assets/js/88.73d31df8.js"><link rel="prefetch" href="/assets/js/89.6d4e53cb.js"><link rel="prefetch" href="/assets/js/9.d01dceaa.js"><link rel="prefetch" href="/assets/js/90.0129f07f.js"><link rel="prefetch" href="/assets/js/91.d16664ce.js"><link rel="prefetch" href="/assets/js/92.06e8dcff.js"><link rel="prefetch" href="/assets/js/93.b5b18dd9.js"><link rel="prefetch" href="/assets/js/94.84d5e718.js"><link rel="prefetch" href="/assets/js/95.eb85deaa.js"><link rel="prefetch" href="/assets/js/96.a9514789.js"><link rel="prefetch" href="/assets/js/97.8b1d193f.js"><link rel="prefetch" href="/assets/js/98.82feff02.js"><link rel="prefetch" href="/assets/js/99.7f6f4c17.js">
    <link rel="stylesheet" href="/assets/css/0.styles.9553969a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><!----> <span class="site-name">weigao</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/algorithm/" class="nav-link">Algorithm</a></div><div class="nav-item"><a href="/commits/" class="nav-link">Commits</a></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>TensorFlow</span> <!----></p> <!----></section></li></ul> </aside> <main class="page"> <div class="content default"><h1 id="tensorflow"><a href="#tensorflow" aria-hidden="true" class="header-anchor">#</a> TensorFlow</h1> <p>Tensorflow中一些简单但是容易忘记的：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token comment">#用来表示矩阵的乘法操作</span>

weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#偏置项</span>
</code></pre></div><p>tf.Variable为初始化变量的操作，tf.random_normal指定了一个2*3的矩阵，元素均值为0，标准差为2，并且，符合正态分布，其他的可以参考tensorflow随机数生成函数</p> <p>接下来这段代码实现神经网络的<strong>前向传播</strong>过程</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>

sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>关于placeholder</strong>
一般而言，我们需要使用常量：</p> <p><code>x = tf.constant([[0.7,0.9]])</code></p> <p>但是这样明显加大了tensorflow的计算量，所以引入了placeholder，这时候我们只需要将数据传入计算图，下面是一个例子：</p> <p><code>x = tf.placeholder(tf.float32,shape = (1,2), name = &quot;input&quot;)</code></p> <p>其中的shape属性可以不指定，因为数据的维度信息可以根据提供的数据推导得出，但是确定的维度的给出可以降低出错的概论。下面的代码为placeholder实现前向传播算法：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>

<span class="token comment"># print(sess.run(y))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>需要注意的是被注释的那行代码<code># print(sess.run(y))</code>，如果运行的话，解释器会报告一个错误，这是因为我们需要提供一个feed_dict来指定x的取值。
如果我们需要多个样例的传播结果，只需要：</p> <p><code>x = tf.placeholder(tf.float32,shape=(3,2),name=&quot;input&quot;)</code> #3个</p> <p>然后给出三组数据即可：</p> <p><code>sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]})</code></p> <p>而后我们定义loss函数来刻画预测值和真实值之间的差距，然后通过反向传播算法来调整神经网络的取值从而缩小差距</p> <div class="language-python extra-class"><pre class="language-python"><code>cross_entropy <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>y_ <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
</code></pre></div><p>cross_entropy定义了真实值和预测值之间的<em>交叉熵</em>。
具体而言，交叉熵刚开始的意义是刻画了两个概论分布之间的距离，是分类问题中使用比较广的一种损失函数。在代码中的含义就是y`表示正确结果，y代表预测结果,并且将张量中的数值限制在1E-10~1.0之间，以避免一些运算错误
如果与softmax一起使用的话，tensorflow对这两个功能进行了统一封装，调用</p> <p><code>cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)</code></p> <p>下面是训练过程开始的代码：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    STEPS <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> dataset_size<span class="token punctuation">)</span>

        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">,</span> y_<span class="token punctuation">:</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            total_cross_entropy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training steps,cross entropy is %g&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>total_cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>训练循环了5000次，可以观察到交叉熵的值是越来越小的，这表明预测的结果和真实值的差距越来越小
最后的两行输出表示训练之后神经网络的值</p> <p>**总结一下，训练神经网络的过程可以分为以下三个步骤：</p> <ul><li>定义网络的结构和前向传播的输出</li> <li>定义损失函数和选择反向传播优化的算法</li> <li>生成会话并且在训练数据上反复运行反向传播优化算法**</li></ul> <p>有的时候需要自定义损失函数：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> RandomState

batch_size <span class="token operator">=</span> <span class="token number">8</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'x-input'</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'y-input'</span><span class="token punctuation">)</span>

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>seed <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>

loss_less <span class="token operator">=</span> <span class="token number">10</span>
loss_more <span class="token operator">=</span> <span class="token number">1</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>y<span class="token punctuation">,</span>y_<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>y<span class="token operator">-</span>y_<span class="token punctuation">)</span><span class="token operator">*</span>loss_more<span class="token punctuation">,</span><span class="token punctuation">(</span>y_<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>loss_less<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

rdm <span class="token operator">=</span> RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
dataset_size <span class="token operator">=</span> <span class="token number">128</span>
X <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>dataset_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token operator">+</span>x2<span class="token operator">+</span>rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">10.0</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token keyword">in</span> X<span class="token punctuation">]</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    Steps <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>dataset_size<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre></div><p>以上自定义了一个损失函数，实际值和预测值之间存在的差值分配不用的系数，我们也可以使用均方误差(MSE)：</p> <p><code>loss = tf.reduce_mean(tf.square(y_-y))</code></p> <p>通过比较输出的结果可以看出，不同的损失函数会对模型产生重要影响。</p> <p>在优化参数的时候，梯度下降法是最常用的神经网络优化算法，具体而言，对于一个优化算法而言，第一步随机产生一个参数的初始值，然后通过梯度和学习率来更新参数的取值。
梯度下降算法的两个缺陷：第一是可能得到局部最优的结果，第二是计算时间太长，因为要计算所有训练数据的损失函数是非常耗时间的，所以就可以使用随机梯度下降算法，具体而言，就是在每一轮的迭代中，随机优化某一条训练数据上的损失函数，但是随机梯度下降法有的时候甚至无法达到局部最优，所以一般采用<strong>每次计算一小部分训练数据的损失函数</strong>的方法，这一小部分数据称为一个batch。</p> <p>对于learning_rate，常用的是指数衰减法</p> <div class="language-python extra-class"><pre class="language-python"><code>global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span>global_step<span class="token punctuation">,</span> <span class="token number">100</span> <span class="token punctuation">,</span> <span class="token number">0.96</span> <span class="token punctuation">,</span>staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>dacay_steps代表了完整的使用一遍训练数据所需要的迭代轮数（总训练样本数除以每一个batch的训练样本数），staircase的值为True时，global_step/decay_steps会被转化成整数。上面各个参数的含义是每训练100轮后学习率乘以0.96。经验有助于设置好学习率、衰减系数和衰减速度。</p> <div class="language-python extra-class"><pre class="language-python"><code>batch_size <span class="token operator">=</span> n

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>

loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
	<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
		current_X<span class="token punctuation">,</span>surrent_Y <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
		sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_sict <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>current_X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>current_Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre></div><p>以上代码概括了一般神经网络的训练大致遵循的过程。</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">4/28/2019, 5:57:40 PM</span></div></footer> <!----> </main></div><div class="global-ui"><!----><!----></div></div>
    <script src="/assets/js/app.8c2dddc1.js" defer></script><script src="/assets/js/5.cd1db3e5.js" defer></script><script src="/assets/js/69.6a56611b.js" defer></script><script src="/assets/js/23.2c687b63.js" defer></script>
  </body>
</html>
